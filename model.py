import torch
import torch.nn as nn
from torchvision import models


def build_model(num_classes: int):
#здесь берем модель ResNet18 из библы торча, со слоями для разнознавания картинок -- ImageNet
#ResNet18 - модель из CNN
#Она отличается от других моделей тем, что позволяет учиться просто на входах и выходах слоев, пропуская инфу о преобразованиях при прохождении данных через слои
#Глобально в ней 10 слоев:
#Conv2D -- сверточный слой, в нем мы получаем признаки модели (как и в других CNN)
#BatchNorm2RD -- нормализуем цифры после Conv2D, чтобы они были в нормальных диапазоне, чтобы не скакал масштаб у данных -- вычитаем среднее и делим на стандартное отклонение (11.38)
#ReLU -- ставим вместо отрицательных значений 0 (потому что когда Conv2D ищет признаки, он же выставляет признаки в зависимости от уверенности модели в совпадения фильтра и признака
#MaxPool -- сохраняет после ReLU самые сильные признаки чтобы не на всех подряд учиться (ResNet18 обычно находит 64x64 признака одной картинки, MaxPool отбирает самые сильные)
#работает по принципу находит в матрице кусок 3 на 3 и ходит по матрице с шагом 2 (это такие настройки я поставил)
#Далее идут 4 Resudail блока, -- особенность модели ResNet -- в ней модель и учится находить закономерности 
#AdaptiveAvgPool2d -- здесь модель усредняет полученные признаки, и превращает в тензор (в нашем случае это 3-мерное представление 65 * 65 * 65)
#FC -- здесь модель как раз и распределяет картинки по признакам на классы (в базовом модели их 1000)
    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)

    # Размер входа последнего слоя
    in_features = model.fc.in_features

    # Здесь для честности творческом работы заменим последний слой FC на наши 3 класса -- овощи, продукты в упаковке, фрукты (они так распределены в датасете)
    model.fc = nn.Linear(in_features, num_classes)

    return model


def count_trainable_parameters(model):
#Функция для отчета -- посчитать на скольких параметрах обучалась модель (у ResNet 10 миллионов параметров, 18 слоев, у каждого слоя X фильтров, а каждый 
#фильтр -- это по сути числовая формула, в которой есть параметры w1 * x1... и получается формул так много что аж 10 миллионов параметров)
    return sum(p.numel() for p in model.parameters() if p.requires_grad)
